def relu(z):
    return max(0, z)

def dnn_2_3_3_1(x, y):
    # 第一隐藏层 z = w·x + b
    z1 = w1[0]*x + w1[1]*y + b1
    z2 = w2[0]*x + w2[1]*y + b2
    z3 = w3[0]*x + w3[1]*y + b3
    print("第一层 z:", z1, z2, z3)
    
    a1 = relu(z1)
    a2 = relu(z2)
    a3 = relu(z3)

    # 第二隐藏层：输入是第一层的输出 a1, a2, a3
    z4 = w4[0]*a1 + w4[1]*a2 + w4[2]*a3 + b4
    z5 = w5[0]*a1 + w5[1]*a2 + w5[2]*a3 + b5
    z6 = w6[0]*a1 + w6[1]*a2 + w6[2]*a3 + b6
    print("第二层 z:", z4, z5, z6)

    a4 = relu(z4)
    a5 = relu(z5)
    a6 = relu(z6)

    # 输出层：输入是第二层的输出 a4, a5, a6
    output = wo[0]*a4 + wo[1]*a5 + wo[2]*a6 + bo
    return output

# 第一层参数（输入 -> 第一隐藏层）
w1 = [0.2, -0.3]; b1 = 0.1
w2 = [0.4, 0.5];  b2 = -0.2
w3 = [-0.6, 0.1]; b3 = 0.3

# 第二层参数（第一隐藏层 -> 第二隐藏层）
w4 = [0.3, -0.5, 0.2]; b4 = -0.1
w5 = [-0.4, 0.1, 0.6]; b5 = 0.2
w6 = [0.7, 0.3, -0.2]; b6 = -0.3

# 输出层参数（第二隐藏层 -> 输出）
wo = [0.7, -0.5, 0.2]; bo = 0.1

# 测试
output = dnn_2_3_3_1(0.5897949215, 0.7277078279)
print("预测结果:", output)
